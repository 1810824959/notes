<h1>5.1</h1>

1.想法
<ul>最近几天各种杂事，没有真正静下心学习，但是也思考了很多另外的东西，列一下</ul>

	1.笔记上写的东西越来越多，但是好多记下又忘了，一定要定期复习!!!
	2.面试的准备，很多要现在开始准备了，打有准备的仗（本地单开一帖）
	3.面经要看，在收藏里头
	4.优秀的人太多，需要追赶的人也太多，我还有自己的一些小小的私心，想要有所成就去找她，不能这样随便的放弃

2.小疑问
<ul>1.他们平时mongo数据都是怎么导出的？？？</ul>



<h1>5.2</h1>

1.类加载机制和类加载器
<ul>1.类加载机制：加载，验证，解析，准备，初始化</ul>

	准备阶段，给类变量（static变量）赋值，0或null
	初始化阶段，先静态，再普通，最后构造

<ul>2.类加载器</ul>

	Java中类加载分两种，1.自带的装载，也就是new，2.手动装载，就是Class.forname()这种的，多用于反射

	而java在虚拟机启动时，会自动装载程序运行的基础类，另外的在用到时才会装载，这样就节约了内存，也算是动态性的体现。

	###类加载器具体分类（自顶向下）
	1.bootstrap loader：这是启动时的类加载器，并不是java写成的，是C++，负责加载JRE/lib/里面的class，和-Xbootclasspath参数指定的路径里的类（并且要符合命名规范，比如rt.jar ，否则放在lib里，也不会加载）

	2.Extension loader:扩展的类加载器，负责加载JRE/lib/ext里的class，和java.ext.dirs系统变量指定的路径中类库

	3.application loader:应用级（系统级）类加载器，负责加载classpath下的类和jar，通常ClassLoader 的 getSystemClassLoader()返回的就是这个

	4.自定义类加载器：继承java.lang.ClassLoader，并重写父类的findClass方法，例如tomcat之类的容器都有自己类加载器，而且不太一样，优先加载自己的，没有再去向上委托


	###双亲委托机制
	需要加载一个类时，先是下面的类加载器拿到，然后委托给父加载器，父加载器不能加载，才下放，这样就保证了比如 Object这种顶层类不会加载错误，即使你下面重写了一个自己的Object类，也不会被加载，因为该类早在启动时就加载好了

	注意有一点，虽然Ext的父加载器是null，所以打印时，显示Null，因为bootstrap是C++实现的，java虚拟机没有相应的class类，但是当向上委托时发现父类加载是空，就会用启动类加载器，道理是一样的
	
<ul>3.反射</ul>

	###反射常见的有两种api
	Class.forName(Name)  //默认初始化
	ClassLoader.loadclass(className)  //默认不链接

	像JDBC用的就是Class.forName() ,因为DriverManager注册等的代码，都是写在static块中，需要初始化
	
<ul>4.补充</ul>

	事实上，jvm判断两个类是否相等，用的类加载器，所以，即使是同一个类或者同一份代码，用不同类加载器加载，也是不同的class对象，equals也是不一样的


<h1>5.3</h1>

1.想做
<ul>1.查看每个类的重写的equals方法，和hashcode()</ul>


2.八种基础数据类型
<ul>1.哪8种：</ul>

	###四种整数类型
	byte(8位)  -2^7~2^7,
	int(32位),
	long(64位),像这种，就要在数字后面加 L 
	short(16位)

	###两种浮点数类型
	float(32位)，加 F 或 f
	double(64位),加 D 或 d
	浮点数是不精确的，不能做精确比较

	###一种字符类型和布尔类型
	char(16位)
	boolean



<h1>5.4</h1>
**1.String常量池**
<ul>1.jvm相关概念回顾</ul>

	###JDK7
	方法区存：类信息，常量池，静态变量
	所以String常量池也在里面

	###JDL8
	把常量池，还有静态变量都迁到了堆上，作为其中的一块区域

	###
	Integer、Byte、Short、Long、Character、Boolean等类型实现了常量池

<ul>2.String常量池作用：1.减少相同字符串频繁创建的消耗，而且像一种缓存，提高性能  2.在某些字面量拼接时，效率会更高</ul>

<ul>3.不同的创建字符串的方式</ul>

	### 
	String str2 = new String("abc");

	上面的语句发生了什么？？创建了两个对象，和一个引用。
	1.首先查询常量池是否有"abc",发现没有，就在常量池创建"abc"的对象，然后在堆上创建一个String对象，引用前面的"abc"，最后用 str2 引用

	###
	String str2 = "aaaa";
	
	这句就是只在常量池创建一个对象，而如果是 String str2="abc"，这样就不用创建对象，因为原来的常量池里面已经有了。

	###
	再总结下，字面量的拼接，直接存结果，而运行期才知道的变量，是会存在堆上的。而final修饰的变量，编译时期就弄好了。

	每个new String对象都是不一样的，而字面量的拼接，只会存结果

	### intern()
	这个方法，把字符串注册进常量池中，看起来有点多余，明明new String也会加进常量池，但是new String返回的对象在堆上，而interb返回的对象，就是在常量池上


**2.String类型不可变**
<ul>1.String是引用类型</ul>
	
	首先，String不是基本数据类型，是引用类型，是存放在堆上的，而且因为是不可变的，所以每次更改，比如 += 都是重新拷贝一份，对原来的不改变，这也就导致字符串这种，用完即扔，等待垃圾回收

<ul>2.String的不可变怎么实现的</ul>

	jdk8源码
	public final class String implements Serializable, Comparable<String>, CharSequence {
	    private final char[] value;
	    private int hash;

	###
	String本质是char数组，这里用的final其实是保证引用不变，但是数组里面的元素还是可以变的，但是被封装死了，没有setFValue的方法，而且是private，所以不可变了

	###注意
	final关键字不仅不可变，而且不可被继承

<ul>3.String为什么要不可变</ul>

	1.为了保证String常量池可以实现。可以变来变去，常量池就没有意义
	2.多线程安全，可以多出共享
	3.计算hashcode的时候，因为不可变，所以不会变来变去，计算一次就行了，很方便，所以比如map的key就是用的String
	4.类加载的安全性，因为类加载要用到字符串，不可变才能保证JVM安全



<h1>5.5</h1>

1.杂，疑问
<ul>1.hbase??</ul>
<ul>2.回去面经的加上，线程池的使用，就在那个hl_node里面，还有那个webmagic的架构咋样</ul>


<h1>5.6</h1>

**1.JVM回顾**
<ul>1.每一个方法都会创建一个栈，都有自己的局部变量表等，栈深超出设定，报错栈溢出StackOverflowError，内存不够就报超出内存，OOM</ul>
<ul>2.虚拟机栈</ul>

	1.局部变量表
	2.操作数栈，大致和局部变量表一样，但是这是用来做数的处理的，比如加减之类的
	3.方法返回地址
	4.动态引用（不管）

**2.java的多态（重载和覆盖）**	
<ul>重载</ul>

	重载简单来看，就是同一个方法，不同的参数，使用的时候根据不同的参数，调用不同的方法

	###
	重载是java静态分派的经典实现。
	比如 Person p = new student();  传入foo()方法里，是调用Person类型的重载？还是student类型的重载？这里Person是静态类型，student是实际类型，静态分派中，需要在编译时期就确定下来，所以重载是用静态类型确定的，这里调用person的重载


	###疑问？
	重载只能发生在同一个类里吗？父子间的重载可以吗？
		public class A
		{
		    public void a(int x){}
		}
		
		public class B extends A
		{
		    public void a(Object x){}
		}
	
	一种说法，两个a方法既不是重载，也不是重写，完全没关系，另一种说法，算是重载，因为子类相当于也继承了A的a方法
	
	
<ul>重写 @Override可有可无</ul>

	重写发生在父子类中，继承的时候只可以继承public和portected，所以private没有重写的可能，重写的时候，访问权限可以改，但只能更大，返回要一样

	###
	相比重载的静态分派，重写是动态分派的一种，就是根据实际类型来选择调用的

<ul>区别</ul>

	重载对返回没要求，而重写访问权限要么不变要么更大，返回要一样，而且不能声明更多异常
<ul>静态分派(重载)和动态分派(重写和其他)</ul>


**3.父类作为句柄声明子类**
<ul>注意点</ul>

	###
	父类声明子类，所以是父类的句柄指向子类的对象空间
	1.只能通过父类访问父类有的属性（也就是对子类而言，只能访问到子类继承过来的东西），如果父类某方法是private，不能被继承，就会调用父类的方法
	2.子类中重写了方法，用父类声明的时候，就会调用子类的方法，要重写哦
	3.子类调用super的父类的相应方法，父类再调用被子类重写过的，就会调的是子类的方法



<h1>5.7</h1>

**1.杂**
<ul>1.计算机最小单位是位(bit，比特)，然后是1字节(8bit)，字节也叫做byte,B</ul>、
<ul>2.java魔法数字:魔法数字本质上就是代码中出现的数字，但是为了代码一目了然，最好使用常量或者枚举</ul>



**2.贪心算法**
<ul>1.分发糖果：对孩子和糖果都排序，用每一个糖果去满足符合要求的最小孩子</ul>
<ul>2.跳跃游戏55：</ul>

	我先是提出一种递归想法，但是时间超出，改用循环
	循环有两种for 和 while ，这里用的是while
	###
	保存一个最远值，index不断向后，while(index<max)，当最远的能达到目标就return
	
<ul>3.跳跃游戏升级45</ul>

	这次要求不一样，假设一定能到最后一个点，要求的是最小的跳跃次数

	###动态规划
	创建伴生数组，全设为最大，第一个为0，并设置一个最远的距离，初始0，遍历，当跳跃距离大于最远，就更新，次数+1

	###总结
	动态规划，一个模板走天下，要么递归，要么用数组
<ul>4.活动选择：每个活动都有自己的开始时间和结束时间，可能会互相冲突，要求一段时间里，能做的最多的活动</ul>

	###动态规划
	假设是 i 到 j 这段时间，里面有个k活动 ，那个最大 c[i,j]=c[i,k]+1+c[k,j]，但是k 不知道是哪个，所以要遍历，子问题的终止条件是，开始时间和结束时间相等或大于

	###贪心算法
	每次都找最早结束的，或者最晚开始的


<h1>5.8</h1>

1.杂
<ul>1.IO密集型和cpu密集型忘了</ul>
<ul>2.mongo的导入和导出</ul>

	mongodump -h 172.16.5.191:17017 -d securityEvent -c hidelink.blankkeyword -o D:/MongoDB/dump

	mongorestore -h 127.0.0.1:27017 -d securityEvent -c hidelink.blankkeyword D:/MongoDB/dump/securityEvent/hidelink.blankkeyword.bson
<ul>3.java 队列（线程安全）？？？concurrentlinkedqueue使用场景？？</ul>
<ul>4.webmagic</ul>
<ul>5.springcloud</ul>
<ul>6.es爬虫？</ul>
<ul>7.web高并发？抢票？？</ul>
<ul>8.https://www.cnblogs.com/Jansens520/p/8624708.html</ul>
<ul>9.https://yuzhouwan.com/posts/190413/</ul>

3.@Value的注入在什么阶段？？比类初始化早吗



<h1>5.9</h1>

**1.杂**
<ul>1.同时把多个字符串replace成"":</ul>

	String src = "南京市玄武区北京东路徐州市鼓楼区戏马台";   
    src = src.replaceAll("(?:江苏省|玄武区|鼓楼区)", "");  

<ul>2.IDEA快速定位到报错处 ：F2</ul>
<ul>3.concurrent包</ul>


线程池源码中，自带有任务队列，但这个队列是给任务准备的，也就是说，排队的是Runnable

**2.线程池**
<ul>1.为什么要用到线程池：1.不需要关心对线程的创建销毁，使用完后自动放回池子。  2.实现了对线程的复用，不用频繁创建销毁，节约成本</ul>
<ul>2.相关类的描述</ul>
![](img/2019-5/1.png)

	###Executor
	这个接口内容很少，且只有一个方法，execute(Runnable r)，作为一个最基本的单元

	###ExecutorService
	拓展了Executor的功能
	
	###ScheduledExecutorService
	继承了ExecutorService，增加了调度功能

	###Executors
	这是个类，唯一的作用就是创建线程池，创建不同的线程池

	###图中另外两个类，就是具体实现，最主要是ThreadPoolExecutor
![](img/2019-5/3.png)

**3.ThreadPoolExecutor源码分析**

	private final BlockingQueue<Runnable> workQueue;  // 任务队列，我们的任务会添加到该队列里面，线程将从该队列获取任务来执行
	private final HashSet<Worker> workers = new HashSet<Worker>();//任务的执行值集合，来消费workQueue里面的任务
	private volatile ThreadFactory threadFactory;//线程工厂
	private volatile RejectedExecutionHandler handler;//拒绝策略，默认会抛出异异常，还要其他几种拒绝策略
	private volatile int corePoolSize;//最下保活work数量
	private volatile int maximumPoolSize;//work上限
	private long keepAliveTime //非核心线程的闲置时间

	###当exxcutorService进行submit时，会往上调用，在ThreadPoolExecutor中，corePoolSize是设置的阈值，maximumPoolSize线程池大小，若执行线程数量<corePoolSize就创建并执行


<h1>5.10</h1>

**1.杂**
<ul>1.线程池报错NullPointerException，这个是在使用execute()的时候才有的，换成submit就Ok</ul>


**2.线程池工作流程**

	1.首先执行submit或者execute，终究会走到ThreadPoolExecutor的excute()，这时候判断正在执行的线程个数是否小于核心线程数，小于就啥事没有，添加worker，并传进任务参数（addWorker方法传参，本身并不加进队列，直接执行），执行就好了

	2.大于等于核心线程数，走下一步，判断池子是否活着，并把任务加进队列，如果都OK，在检查一遍池子活着吗，死的就删除队列中的该任务，并拒绝，活着在检查下，执行的worker是不是为0，是的话，就加一个空的worker（这里不管咋样，都已经加进了队列，总会被worker消费的）

	3.第二步骤中，判断池子活着并加队列的操作，如果失败，就到了这里，这里会尝试使用maximumPoolSize来addWorker，如果再失败，就拒绝（注意哦，这里创建的就是非核心worker，会有keepAliveTime的限制时间）

3.线程池静态工厂
<ul>1.底层实际执行的方法</ul>

	public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue)

<ul>2.newSingleThreadExecutor:单线程的线程池，保证是按照先进先出的顺序执行，而且在一个线程异常结束后，会创建一个新线程顶上，但是并不是想象中的继续上一个线程的工作，而是执行下一个任务</ul>

	new ThreadPoolExecutor(1, 1,
                       0L, TimeUnit.MILLISECONDS,
                       new LinkedBlockingQueue<Runnable>())

	##用的是无界队列

<ul>3.newFixedThreadPool：</ul>
	
	new ThreadPoolExecutor(nThreads, nThreads,
                           0L, TimeUnit.MILLISECONDS,
                           new LinkedBlockingQueue<Runnable>());

	这里可以看到，因为不需要回收，corePoolSize和maximumPoolSize都是设的一样的，而且keepAliveTime=0，说明根本不需要规定核心线程数这种东西，完全是定长，因此，用的也是无界队列LinkedBlockingQueue

<ul>4.newCachedThreadPool:无界线程池，可回收线程，空闲60s即回收</ul>

	new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                      60L, TimeUnit.SECONDS,
                      new SynchronousQueue<Runnable>()

	###
	看参数可知，该线程池根本没有worker数量的限制，也就是不限制线程数量，完全按照机器性能来，而且这里不用无界队列了，用的是SynchronousQueue，这个想要添加，必须先取出一个，刚好适合直接提交的策略

<ul>5.newScheduledThreadPool:支持周期任务</ul>



<h1>5.12</h1>

**1.今日想做**
已经移到下一日


**2.线程池**
<ul>1.情景：如果一次性提交大量任务怎么办</ul>

	单线程的：第一个进来，直接addWorker，由于是无界队列，所以根据逻辑，加进队列
	定长：核心线程数等于普通线程数，是无界队列，所以小于核心线程数时，直接add，大于的时候，加入队列，但是线程数已经不会再增加了
	可回收：核心线程数0，最大值无限，队列用的是SynchronousQueue，并且存活时间是60s，在这里，已经没有核心线程的概念，第一次添加就直接走队列，然后addworker(null)用于消费，第二次加，因为队列是一进一出的，所以加入队列失败，会根据maximumPoolSize来addworker，这样线程数量就没有上限了，所以在这里加入存活时间，闲置60s就回收

<ul>2.内置队列的排队策略</ul>

	###
	直接提交，队列基本不存任务，直接就甩给线程去执行，典型是SynchronousQueue，但这种需要最大线程数很大，不然会一直拒绝

	###
	无界队列，任务可以一直积累起来，所以就根本用不上最大线程数的设置，所以定长线程池都设为一样，这个要注意，任务积累速度不能过分超过消费速度，不然队列内存占用会很大

	###
	有界队列，队列有数量限制，这个在jdk中没有用到，需要自己定制，当最大线程池，或者队列最大长度过小，就会频繁拒绝，所以较为麻烦

<ul>3.拒绝策略</ul>
	
	###CallerRunsPolicy
	public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
           if (!e.isShutdown()) {
               r.run();
           }
      }
	
	当要拒绝的时候，调用该任务自身的execute方法，不通过线程池来做

	###AbortPolicy
	public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
           throw new RejectedExecutionException();
    }

	这种策略，会抛出异常

	###DiscardPolicy
	这个方法里连内容都没有，直接不管这个任务，相当于丢了，但是不报错

	###DiscardOldestPolicy
	public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
           if (!e.isShutdown()) {
               e.getQueue().poll();
               e.execute(r);
           }
    }

	准备拒绝时，把队列最早一个poll，再继续执行
	
<ul>总结：keepAliveTime和maximumPoolSize及BlockingQueue的类型均有关系。如果BlockingQueue是无界的，那么永远不会触发maximumPoolSize，自然keepAliveTime也就没有了意义。
反之，如果核心数较小，有界BlockingQueue数值又较小，同时keepAliveTime又设的很小，如果任务频繁，那么系统就会频繁的申请回收线程。</ul>



**3.Queue接口**
![](img/2019-5/4.png)
<ul>1.queue本身是先进先出的，queue自己就有实现类，比如PriorityQueue，用Comparable来实现排序，不是单纯的先进先出，再有就是LinkedList，既可以作为双端队列，也是一个集合可以用下标获取元素</ul>
<ul>2.blockQueue</ul>
	
	* ArrayBlockingQueue ：一个由数组支持的有界队列，可以指定公平或者非公平。
	* LinkedBlockingQueue ：一个由链接节点支持的可选有界(或无界，不指定容量，是Integer.MAX_VALUE)队列。
	* PriorityBlockingQueue ：一个由优先级堆支持的无界优先级队列。
	* DelayQueue ：一个由优先级堆支持的、基于时间的调度队列。
	* SynchronousQueue ：内部不存在数据缓存的东西，进一个出一个。
	
<ul>3.方法</ul>

	###queue接口（非阻塞）
	add:boolean，满了会抛出IllegalStateException
	remove：E，返回元素并移除，为空NoSuchElementException
	element ：E，返回头部元素，为空NoSuchElementException
	offer：boolean，满了返回false
	//offer()：boolean，等待一段时间    
	poll:E，返回头部元素并移除，为空返回Null（所以不允许插入null）
	//poll(time, unit):等待一定时间
	peek:E，返回头部元素但不移除，为空返回Null

	###blockQueue（阻塞）
	put:void，满了会阻塞等待    
	take：E，为空会阻塞等待       


**4.杂**
<ul>1.java 生成从n到m的随机整数</ul>

	int b=(int)(Math.random()*10);//生成[0,9]之间的随机整数。
	int temp=m+(int)(Math.random()*(n+1-m)); //生成从m到n的随机整数[m,n]
	random.nextInt(m)表示生成[0,m-1]之间的随机数，也就是说random.nextInt(m+1)，将生成[0,m]之间的随机整数



$and:[{"reliability":1},{"isValidate":1}]


<h1>5.14</h1>

**1.今日想做**
已移到下一日

**2.杂**
<ul>1.java公平机制的概念，公平就是符合先进先出(FIFO)</ul>


**3.不同线程池的选用**

	SingleThreadExecutor:一个一个按顺序来，所以适合必须按顺序跑的场景，但是这样一来感觉没啥用，但其实不是，同一个线程复用也是节省了资源
	FixedThreadPool：定长的，线程创建了就没想过要回收，所以适合一些长期的任务，不过任务提交频率不能太快，不然阻塞队列会很占内存
	CachedThreadPool：队列虽然是一个拿走一个来，但的确还是并发的，因为线程有回收，所以适合短期的小任务

	###那么提交速度大于处理速度咋办
	我觉得可以定制线程池，用有界队列 



<h1>5.15</h1>

**1.今日想做**
已移到下一天


**2.阻塞队列实现原理**
<ul>阻塞方法（put,tack）：首先加上可重入锁，判断队列满或者空，进行await()，不满足就进行插入，最后放开重入锁（这里用的是Condition来await，不是很懂）</ul>
<ul>改成同步的非阻塞方法（从queue方法继承来）:也是用的重入锁，这里的锁和前面阻塞方法的虽然是同一把，但由于不是一个线程的，所以不能重入，做到了同步</ul>


**3.可重入锁(synchronized也是重入锁 )**
<ul>1.为什么使用可重入锁：一个方法中占用了锁，但是他要调用另一个也要用到锁的方法，这样就会阻塞，造成死锁，导致这个方法独占的锁一方面不会释放，被调用的方法也拿不到锁，卡在这里</ul>
<ul>2.实现原理</ul>

	ReentrantLock本身最核心的两点，1，实现了Lock接口，2，有一个内部类Sync，继承了AQS(AbstractQueuedSynchronizer)抽象类，并有公平和非公平两个子类

	###上锁
	一个锁，最重要的就是上锁和释放锁过程，上锁，调用的是sycn的lock，里头调用AQS的acquire方法。

	acquire具体点，首先是调用tryacquire方法，这个一般由子类实现，能得到锁，就完事了，得不到，就再调用addWaiter，把当前线程加进链表中，让他等待着

	tryacquire由子类实现，在重入锁中，就是公平锁和非公平锁的实现，两者都实现了基本相同的功能：先获取state，若等于零，就获得锁，return true，不等于零时，else if独占的线程是不是当前线程，是就增加state，都不符合，就return false。两者的唯一区别，公平锁会判断一下，链表里有没有等待的node，有就直接return false，保证按照链表来

	###释放锁
	这个公平不公平倒是都一样，还是最终调的是AQS中的release，里面调用的tryrelease是在子类中实现的。

	tryrelease获得state，减去释放的量，如果等于，就释放了锁

<ul>3.总结</ul>

	总的来说，重入锁，一方面实现了Lock接口，一方面创建了继承AQS的内部类，并衍生了公平与非公平的子类

	https://www.jianshu.com/p/f47250702ee7


**4.AQS**	
<ul>这个框架类是Lock类的基础，里面是要是acquire，release方法，还有在子类中会被重写的相应的tryacquire和tryrelease方法，使用方法大体参照重入锁写法</ul>
<ul>里面有一个volatile int state变量，作为同步变量；还有一个链表，作为线程阻塞等待的队列，head节点，永远指向的是当前独占的线程，里面元素是封装好的Node数据结构，里面用一个int来标识状态，当大于0就是线程被取消了，不用抢占了</ul>



<h1>5.16</h1>

**1.今日想做**



**2.Condition等待唤醒机制**
<ul>1.synchronized关键字和 object.wait()和notify() 可以实现内置的等待通知模式，而Condition接口也可以实现</ul>
<ul>2.源码结构</ul>
	
	condition是个接口，唯二的实现子类中，最常见的，是AQS的内部类ConditionObject，而这个内部类，会在Lock的newCondition中被使用，用来返回当前锁的条件变量，使用也很简单，await,signal和变体方法

	###经典例子
	await()方法，将把当前线程，组装成Node，装进链表里，同时释放锁，并唤醒链表里后续的节点，这个被await的线程，一直要等到被signal，或者interrupted，才能参与竞争，因为等待的过程是while 该条件的

	比如，阻塞队列中，take方法会阻塞

	public E take() throws InterruptedException {
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();
        try {
            while (count == 0)
                notEmpty.await();
            return dequeue();
        } finally {
            lock.unlock();
        }
    }

	当阻塞队列为空，就把当前队列await()，加进等待链表，等待被唤醒或中断，从而参与竞争，这时候当前锁也释放了，其他线程就可以往里面加东西了，take方法才有可能真正调用（注意，这里的释放是完全释放.fullRelease）

	###
	signal就是唤醒队列最前面的node


**3.Java内存结构，内存模型，对象模型**
<ul>内存结构：就是堆，方法区，虚拟机栈等等</ul>
<ul>内存模型：这个概念是相对于多线程来说的，java为了消除不同操作系统的内存模型的区别，规定了java模型</ul>
<ul>对象模型：具体看链接吧</ul>
<ul>链接：https://mp.weixin.qq.com/s/mJVkLn2I1O7V8jvxc_Z4zw</ul>


**4.volatile**
<ul>1.操作系统的内存模型</ul>

	执行指令时，临时数据都是存储在主存，而读取写入主存的速度，肯定比不上加减之类的执行操作，所以就增加一个高速缓存，需要读取数据，就读缓存中，从主存复制过来的数据，这样就会引发缓存不一致的情况，明明已经改了，但是缓存里面没有改

	###两种解决方法
	1.加锁，但是慢
	2.缓存一致性协议，核心是保证，每一个线程，看到的共享变量，都是最新的，是同一份的。比如在更新值的时候，会令其他缓存中的该值都无效，其他缓存要用的时候，发现无效，就会重新读取
<ul>2.延伸到java 的内存模型</ul>

	由于java是跨平台的，为了消除各个操作系统之间的区别，java抽象的顶一个一个内存模型，分为共享内存和本地内存，体现在jvm就是，共享内存是堆，方法区，本地内存是虚拟机栈的局部变量表，存的是共享内存中的副本

<ul>3.举例</ul>

	//线程1
	boolean stop = false;
	while(!stop){
	    doSomething();
	}
	 
	//线程2
	stop = true;

	###
	线程2修改stop,线程1不会立即做出反应，因为线程1有自己的缓存，线程2改动后不能立即知道。这时候使用volatile，就可以使得该变量具有可见性，线程2修改后，立即写入共享内存，并让另外所有缓存失效

	###
	但volatile，只能解决可见性，不能解决原子性，他只能保证读的是最新的，但是比如自增的操作，是先读，再加，再回写，这样就会出现错误

	###
	所以volatile多用在状态标记，比如上面的例子，或者是double check


<h1>5.17</h1>

**1.多路复用再复习**
<ul>多路复用是阻塞IO还是非阻塞？？</ul>

	答案是，不好说。
	一个用户进程去调用select函数，进程会等待select返回，这个过程是阻塞的，但这个过程和IO本身并不相同，再select返回可读后，进程才会发起IO，而这个IO，一般是置为un-blocking

	所以，多路阻塞等待的是select过程


2.明天要做
<ul>1.收藏夹里那个面经，太可怕了，必须全部掌握</ul>
<ul>2.netty的简单demo搭建</ul>


<h1>5.18</h1>

**1.最短路径算法，带权重的**
<ul>Dijkstra（迪杰斯特拉）算法</ul>

	该算法，给出一个二维数组，存储邻边关系，在设置两个一维数组，一个用来存是否已经用来更新过，另一个存源点到各个点的距离（临时）

	首先，从源点更新，填满之后，从里面距离最短的点，再次从这里更新，直到更新完为止，在之后的遍历过程中，遍历每一个点，用每个点求距离，所以时间复杂度是O(n^2)


<h1>5.19</h1>

- **hashmap再学习JDK7**
<ul>3.14的时候有过学习，现在再来补充</ul>
<ul>1.详解</ul>

	主体是数组，当发生冲突时，就是使用链表，所以当冲突特别大的时候，走的都是链表，复杂度就逼近O(N)了，而且发生冲突，用的都是头插法，插在第一个

	介绍一下最核心的put方法。
	1.首先判断key是不是Null，是就插在第0号位置，所以hashmap的key可以为null，只不过是在第一个而已
	2.算出下标：先hashcode，用该值调用hash方法，得到一个h，然后调用indexFor，里面进行h&(length-1)，得到下标（length-1再用或运算，保证一定落在length的范围内，而且位运算效率高）
	3.算出下标，遍历上面的链表，如果值有了，就更新，返回old值
	4.没有，就添加。在这里如果size大于阈值，且要发生冲突，就resize(2*length)，扩容两倍，这之后再调用transfer，把老map的元素移到新的map，是把每一个链表的头，用头插法插入就行
	5.重算hash和下标，然后插入

	另外的方法比如remove
	就是定位到相应的桶，再遍历，使用equals

	###
	重写equals的话，hashcode也要重写，因为hashmap是用hashcode作为其中步骤得到下标的，这样就会定位到不同的桶，再使用equals遍历就会有问题
<ul>2.为什么扩容要变成2的几次幂：http://www.cnblogs.com/xiaolovewei/p/7993521.html</ul>
<ul>3.啥时候调用resize:1.putAll，要插入的map大于阈值  2.put时，size大于阈值且发生冲突</ul>



<h1>5.20</h1>

**1.hashmap再学习JDK8**
<ul>1.区别</ul>

	1.扩容机制的优化，主要是省去了rehash过程
	2.引入了红黑树，提高了效率
	3.解决了resize时多线程死循环问题，但仍是非线程安全的

<ul>2.扩容机制优化</ul>

	jdk7中，直接New 出个2倍容量的数组，然后调用transfer，里面重新算下标，在头插进去

	jdk8中，考虑到下标是 hash&(n-1)，只需要考虑n-1多出来的那一位对应的hash是0 还是 1，0&1=0，就保持不变，1就加倍，直接就可以得出来，不需要rehash

	http://www.cnblogs.com/twoheads/p/10682275.html

	###
	有一个注意点，jdk7中，resize扩容，由于插入用的是头插法，所以链表会倒置，但是8中，是尾插法，就不会倒置

	###resize补充
	Jdk7中，只有put和putAll才会调用resize
	而JDK8中，有更多的地方用到，因为resize不仅仅是扩容，也包含了初始化的步骤

<ul>3.主要变量</ul>

	1.capacity，桶的数量，默认16	
	2.loadFactor，装载因子
	3.threshold，阈值，是size*loadFactor
	4.TREEIFY_THRESHOLD，默认是8，超过8就把链表转化为红黑树
	5.UNTREEIFY_THRESHOLD ，默认6，小于该值，退化为链表
	6.MIN_TREEIFY_CAPACITY ：最小树化容量 64。当桶中的bin被树化时最小的hash表容量，低于该容量时不会树化

<ul>4.hash方法的不同</ul>

	jdk7很复杂
	jdk8:hash方法中，高16bit不变，低16bit和高16bit做异或，然后hash&(n-1)

	###为啥这样搞，看链接
	https://blog.csdn.net/zjxxyz123/article/details/81111627

<ul>5.put方法</ul>

	1.先对table进行长度检查，为0，就调用resize初始化一个，就用默认值
	2.算出下标，和jdk7差不多，但是校验key=null放在了hash方法里，而且hash(key)是对key值做的
	3.找到那个桶，空的就直接newNode，不空就判断是树结构还是链表，树结构就调用putTreeVal的方法，链表就遍历，找到就赋给 e 变量，找不到就加在最后，同时检查有没有过8，要不要变成树。（这一步总的来说，就是找到旧值，没有就加上，e=null）
	4.找到或没找到，通过e 来判断，Null就是么的，有就覆盖并返回
	5.走的添加路线，而不是覆盖路线的，到了最后一步，size++，如果要扩容就扩容

	###
	resize既可以用来初始化table，也可以用来扩容

	###
	变成树结构，和在树中插入怎么做的
	

**2.hashmap总结**
<ul>1.hashmap允许插入(null,null)，但是意义不大</ul>
<ul>2.不保证插入的顺序</ul>
<ul>3.加载因子过大，遍历会变慢，因为毕竟元素多了，过小，就会频繁出发resize，消耗性能</ul>
<ul>4.不是同步的，要同步需要concurrent包的相关功能封装下</ul>
<ul>5.是fast-fail的</ul>



<h1>5.21</h1>

**1.LinkedHashMap**
<ul>总结</ul>

	1.允许key=null
	2.由于是继承了hashmap，所以除了遍历是有序的，另外都和hashmap一样，也是线程非安全
	3.默认是按照插入顺序，也是传入boolean参数，按照最近访问顺序，最近访问的在最后面
	4.put的时候，key已经存在，不管是插入顺序，还是访问顺序，都是放在链表最后

<ul>2.源码分析</ul>

	1.hashmap桶用的是Node，linkedhashmap继承并拓展，在Node中增加了before和after，来实现链表

	2.所以相应的，put 或者 remove时，重写了newNode之类的方法，对before等前后指针，做了设置

	3.增加了boolean accessOrder，来规定迭代顺序，默认是false，就是插入顺序，可以通过构造方法更改，可以用访问顺序，来实现LRU

**2.Map实现类**
<ul>hashtable在jdk8源码中，并没有与时俱进，实现原理还是jdk7的hashmap版本，顶多是在put/remove上做了同步</ul>
<ul>TreeMap</ul>

	实现了SortedMap接口，对map中的元素进行排序，底层是用红黑树来做的，所以put/remove/get方法，都是lgN的复杂度

	###
	默认是用key的自然排序来做的，也可以在构造方法里传入Comparator实现（像Interger之类的，都是有着自己的CompareTo方法的，已经实现好了）


**3.ArrayList源码分析**
<ul>1.arraylist本质上就是一个容量可变的数组，在add的过程中，会发生扩容的情况，所以在初始化时，预估容量会起到提高效率的作用</ul>
<ul>2.add方法</ul>

	add方法不带参默认插入到最后，过程中判断是否需要扩容，判断条件，是否超出容量，超过就扩容
	add带参，就是index，和要加的list，先判断越界，然后走流程

	###扩容
	默认扩容当前容量的一半，如果还不够，就按照add后的容量来。

	这里会调用一个native函数，System.arraycopy用来拷贝元素到新数组。

	add()时，先扩容，然后令最后一位等于插入元素
	add(index,e)时，也是先扩容，然后外面显式调用System.arraycopy，把index后的元素移到index+1上，然后在index位置插入元素

	add，创建了一个新数组，复制一遍数据；而add带参，创建一个数组，复制两遍数据，更加消耗时间


**4.杂**
<ul>1.hashmap key=null,get的时候get(0)拿不到</ul>



<h1>5.22</h1>

**1.今日想做**
<ul>2.nio,netty</ul>
<ul>3.操作系统中，线程的状态</ul>
<ul>5.数组扩容机制，list扩容</ul>
<ul>6.cas同步机制？？</ul>
<ul>8.Object的各种初始方法，比如wait,notify</ul>
<ul>9.spring设计模式，ioc机制，aop机制</ul>
<ul>10.具体项目</ul>
<ul>11.Java socket</ul> 
<ul>12.concurrentmap，hashmap怎么搞成红黑树的？？？红黑树？？？？</ul>
<ul>13.二叉树的插入删除，红黑树插入删除</ul>


**1.List接口**
<ul>1.LinkedList</ul>

	1.继承关系：实现List接口，和Deque接口
	2.由于实现了双端队列，和ArrayList底层数组不一样，所以直接用下标访问不可以，需要遍历链表，随机访问效率很低，但是插入删除都是O(1)的复杂度
	3.链表嘛，也无所谓重复不重复，有没有Null
	
<ul>2.Vector</ul>

	1.大致和ArrayList相同，但是其中很多方法都是同步的
	2.扩容是扩容一倍

<ul>3.stack:继承Vector，实现了栈的功能</ul>
<ul>4.总结</ul>

	1.ArrayList底层数组，所以按下标查，更新比较快，但是增删，由于要移动后面的元素，所以慢
	2.LinkedList是链表实现，不能随机访问，所以查，更新要遍历，很慢，而增删比较快
	3.Vector，就是同步版ArrayList，但效率低
	4.Stack，先进先出版Vector


**2.Set接口**
<ul>1.HashSet:基本没有自己的东西，都是用的hashmap，只不过hashmap插入的是键值对，hashset插入的是key，value填充了一个new Object()，而且和hashmap一样，不保证迭代顺序</ul>
<ul>2.TreeSet，抄的TreeMap</ul>


**3.哪些容器可以插入null**
<ul>1.hashtable不可以，key和value都不可以，当key=null，在key.hashcode这一步就会NullPointerException空指针，value=null在一开始就报空指针</ul>
<ul>2.带Tree的容器不行，比如TreeMap,TreeSet，因为他们都是要对元素排序的，null插进去没有意义，在compareTo方法中会报空指针</ul>
<ul>3.另外都可以，</ul>


**4.红黑树**
<ul>概念</ul>

	###
	首先是二叉查找树（搜索树），左子树比根小，右子树比根大。平均复杂度是O(lgn)，高度是lgn+1。但是有缺点，比如极端情况，就是一条链表一样的东西，复杂度就是O(N)

	###
	做出改进，希望树高矮一点，就是填的更满一些，规定，左右子树的高不能超过1

	###
	红黑树
	1.根是黑的
	2.若父节点是红，两个子节点，必是黑
	3.空节点，也就是叶子节点的下一层，算黑
	4.每一天路径，到最后的空节点，黑的数目一定一样

<ul>2.红黑树和平衡二叉树的区别？？为什么用红黑树？？</ul>

	###
	平衡二叉树是一种绝对的平衡，旋转次数未知，适用于增删少，查找多的情况

	而红黑树是一种弱平衡，不要求完全符合平衡二叉树，所以相同N个结点，红黑树要高于AVL树，而且，一次插入，最多最多只需要3次旋转就能平衡，性能消耗少

<ul>3.红黑树的三次旋转</ul>

	###插入一个新的节点，默认设置为红
	1.如果原树为空，该节点就是root，改为黑
	2.如果当前节点的父节点是黑，不变，没有影响到红黑树结构
	3.父节点是红，分三种情况

	a.父节点是红，且叔叔节点也是红，这样就把父，祖父，叔叔节点全都变色，并以祖父节点作为新的开始，迭代这样的过程
	b.父节点红，叔叔节点黑，且当前节点是右子树，这样就用当前节点为支点，那就左旋，变成c的情况
	c.父节点红，叔叔黑，当前节点是左子树，那就右旋，并把原来父，祖父节点变色

	###
	所以说，最多经过三次旋转，必可以平衡
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>

<h1></h1>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>

<h1></h1>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>


<h1></h1>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>


<h1></h1>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>


<h1></h1>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
<ul></ul>
